P67-68 MapReduce
2/9

优点：高可用，容错率，海量数据TB/PB

缺点：不适合实时计算（MYSQL,一般都要几个小时几天）
不适合流式计算（一般都是flink比较擅长）
不适合DAG directed acyclic graph (flink) 因为存硬盘不是磁盘

P69-70 
2/11
Map -> 并行计算
Reduce -> 并行合并计算结果

wordcount源码分析，三个步骤
- main
- map
- reduce

P71-72 MapReduce编程规范
2/14
Map需要继承官方的mapper，主逻辑定义在map里，k,v k是offset，v是value
										output k,v
- 每一行做map处理
Reduce也是继承官方的reduce，主逻辑在reduce里，map的输出，是reduce的输入，
- 每一个key做reduce处理

Driver
- 一些规范，比如输出的文件内容，k,v是什么，关联map/reduce

P73-76 mapreduce wc 案例
map
reduce
driver

P77 wordcout debug
2/16

P78 本地模式，windows 环境
- linux虚拟机
打包有两种方法：
- 1.without dependencies
- 2.with dependencies...

hadoop jar wc.jar com.atguigu.mapreduce.wordcount.WordCountDriver /xiyou/huaguoshan /xiyou/huaguoshan/output

bug: 注意，如果输入路径含有folder，会有error，只能含有files

P79-80 Hadoop序列化 & 自定义bean对象实现序列化接口（Writable）

Hadoop序列化比java序列化轻量集，不用额外的信息，简单的校验信息。传输更快
1）什么是序列化
序列化就是把内存中的对象，转换成字节序列（或其他数据传输协议）以便于存储到磁盘（持久化）和网络传输。 
反序列化就是将收到字节序列（或其他数据传输协议）或者是磁盘的持久化数据，转换成内存中的对象。
2）为什么要序列化
一般来说，“活的”对象只生存在内存里，关机断电就没有了。而且“活的”对象只能由本地的进程使用，不能被发送到网络上的另外一台计算机。 然而序列化可以存储“活的”对象，可以将“活的”对象发送到远程计算机。
3）为什么不用Java的序列化
Java的序列化是一个重量级序列化框架（Serializable），一个对象被序列化后，会附带很多额外的信息（各种校验信息，Header，继承体系等），不便于在网络中高效传输。所以，Hadoop自己开发了一套序列化机制（Writable）。
4）Hadoop序列化特点：
（1）紧凑 ：高效使用存储空间。
（2）快速：读写数据的额外开销小。
（3）互操作：支持多语言的交互


P81-82 writeable实际案例 + writable编写
2/17
需要编写序列化和反序列化，这样子传输的时候，才能读，因为Bean不是default的。
    //4 实现序列化和反序列化方法,注意顺序一定要保持一致
    @Override
    public void write(DataOutput dataOutput) throws IOException {
        dataOutput.writeLong(upFlow);
        dataOutput.writeLong(downFlow);
        dataOutput.writeLong(sumFlow);
    }

    @Override
    public void readFields(DataInput dataInput) throws IOException {
        this.upFlow = dataInput.readLong();
        this.downFlow = dataInput.readLong();
        this.sumFlow = dataInput.readLong();
    }

注意：需要无参构造

P83-86 MapReduce案例
2/18
map,reduce,driver, debug运行调试！！！
debug非常重要