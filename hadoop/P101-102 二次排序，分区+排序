P101-102 二次排序，分区+排序
2/26

P103-104 Combiner 合并
挺有意思的，如果可以用的话，可以直接把Reducer当Combiner用，提前combine

P105-106 Output Format
自定义的output，比如oracle，hbase，es等

P107-108 oututFormat案例
2/27
挺好玩的。

P109-110 maptask & reducetask 流程 ** 面试重点

P111-112 2/29
MapTask 源码解析
/tmp/hadoop-shiya/mapred/local/localRunner/shiya/jobcache/job_local1900426249_0001/attempt_local1900426249_0001_m_000000_0/output/spill0.out

P113-114 ReduceJoin
join不同类型的input

Map端的主要工作：为来自不同表或文件的key/value对，打标签以区别不同来源的记录。然后用连接字段作为key，其余部分和新加的标志作为value，最后进行输出。
Reduce端的主要工作：在Reduce端以连接字段作为key的分组已经完成，我们只需要在每一个分组当中将那些来源于不同文件的记录（在Map阶段已经打标志）分开，最后进行合并就ok了。

P115-116 Mapper/Reducer of ReduceJoin
3/1 
获取文件信息，在setup()里面获取，只需要获取一次，不然的话在map里面，每一行就要获取一次。


注意！！！Hadoop取出来的对象不能直接赋值，因为只是地址，需要把value赋值为一个创建为新的创建对象！BeanUtil.copyProperties
